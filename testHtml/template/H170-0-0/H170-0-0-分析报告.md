# XX 项目曲线分析报告

## 目录

[TOC]

<div style="page-break-after: always;"></div>

## 模型训练数据集描述

### 数据集描述

当前算法模型训练模型、验证使用数据量如下所示：

**螺栓号**是指采集曲线的螺栓编号，**曲线数量**表示拟合当前螺栓模型使用的曲线的数量。

**测试集**表示用来检验算法模型准确性的数据集合，比如测试集的大小为25%，则当前数据模型使用75%的数据进行拟合（这75%的数据称为**训练集**），使用25%的数据集对拟合结果（也就是算法模型）进行验证。

| 工位号 | 螺栓号 | 曲线数量 | 比例(测试:交叉验证) |
| :----: | ------ | -------- | ---------- |
  |  | H170-0-0 | 1894 | 60 : 40 |


### 选取特征说明

**特征**：特征是**拧紧曲线**的可观测属性或者特点，且这种属性或者特点可以进行量化。

**为什么需要提取特征？**

在机器学习分类或者预测问题中，区分事物往往不需要事物的全部属性。**且特征提取的优劣直接关系到模型预测的准确性**，如果提取特征后得到的特征具备比较好的**可分性**，可以明确的区分样本，则可以得到比较高的模型预测准确率。并且特征的数量对模型训练时的计算量也会造成影响，因此对于一个优秀的算法模型而言，**特征的提取是最重要的一步，直接影响了最终的结果。**

当前算法模型拟合使用特征描述如下图所示：

|             特征名称             | 说明 | 
|:----------------------------:| ---------------------- | 
| 测量扭矩 | | 
| 分段拧紧数量 | | 
| 最大扭矩 | | 
| 贴合点扭矩 | | 
| 终拧紧段扭矩角度序列均方差 | | 
| 下旋阶段平均扭矩 | | 
| 下旋阶段扭矩方差 | | 
| 下旋阶段扭矩波峰数量 | | 
| 下旋阶段扭矩波谷数量 | | 
| 终拧紧段扭矩波峰数量 | | 
| 终拧紧段扭矩波谷数量 | | 
| 下旋阶段波峰波谷周期 | | 
| 终拧紧阶段波峰波谷周期 | | 
| 终拧紧段扭矩峰峰值 | | 
| 终拧紧段扭矩角度斜率 | |> 模型生成后可以通过**R2 决定系数**计算模型的**拟合优度**。
>
> **拟合优度**可以理解为对算法模型的评分，范围从0到1。从这个分数入手可以对特征的贡献进行评价。

**特征排序**：下图为通过机器学习方法验证后特征的重要性排序。

![][0]

纵轴是特征名称的TOP排序。横轴代表此特征对**拟合优度**的贡献值，可以为正也可以为负，可以理解为**对模型产生的贡献**。

<div style="page-break-after: always;"></div>

## 模型训练和验证过程

**曲线分析模型报告出具步骤：**

1. 采集曲线并过滤有异常的曲线，通过**简单随机抽样**的方式对多个螺栓抽取一定数量（具体为数据集描述中曲线数量）的曲线数据，并按照测试集的比例将数据集分成**训练集**和**测试集**。
2. 使用特征提取算法提取特征，得到**特征向量**。
3. 使用**训练集**的数据训练算法模型。
4. 使用**测试集**的数据对算法模型进行验证，得到准确性、学习曲线、特征排序等评价模型的数据表格。
5. 生成报告对算法模型的**拟合程度**进行可视化说明。

![][1]

## 算法模型的准确性

### 准确性指标

准确性指标是校验算法模型最直观的方法，通过准确性可以量化算法模型的得分（得分范围为1-100），也就是说准确性指标越接近100则算法模型的性能越优越，以下是两种关于算法模型准确性的指标和其侧重点：

|  Precision（精准度）  | Recall（召回率） |
|:----------------:| ---------------- |
| **99.722%** | **99.722%**       |


**预期算法模型预测准确率应该在95%以上，根据数据量不同准确率指标可能存在差异，具体可见下表：**

| 曲线条数 | 100      | 1,000 | 10,000 | 100,000 | 1,000,000 |
| -------- | -------- | ----- | ------ | ------- | --------- |
| 准确率   | 50% ±10% | 60%   | 80%    | 90%     | 95%+      |


**示例**：假如现在有1000条控制器判定OK的螺栓拧紧数据，其中实际发生问题的数据（也就是人为判定为NOK的数据）有120条。算法模型判定100条NOK的曲线数据且其中只有80条是实际发生问题的曲线。

#### Precision（精准度）

> 发现的问题是否准确

精准度侧重点在于**算法模型判定为NOK的**数据中有多少数据是**实际发生问题的**，也就是算法的准确率。示例中算法模型判定100条NOK的数据中只有80条是实际发生问题的数据，则准确率为80%。

#### Recall（召回率）

> 问题发现的是否全面

召回率的侧重点在于**实际发生问题的**数据中有多少数据是**算法模型判定为NOK**的，同样是一种算法的准确性指标。示例中实际发生问题的120条NOK的数据中只有80条是算法模型判定的数据，则准确率为67.7%。



> 在业务中Precision（精准度）和Recall（召回率）是同等重要的指标，可以考虑如果算法模型判定的数据中都是**没有发生问题的**（误报）那算法模型也就失去了实际作用。同时如果有诸多的**实际发生问题的**数据而算法模型没有发现（缺少泛化性），其实算法也是没有意义的。

**那么算法准确性的结论是如何得到的呢？又或者说是如何计算出来的？**

### Confusion Matrix（混淆矩阵）

下图为算法模型预测**测试集**数据得到的匹配结果，其横轴为当前数据中算法模型预测为OK或者NOK的数据量，其纵轴表示实际上（人为判定的）数据为OK或者NOK的数据量。

![][2]

> 通过混淆矩阵可以清晰地查看模型对于数据的预测情况，比如实际上有问题的数据算法模型预测成功了多少个，所占的比例是多少。而算法模型预测出NOK的数据又有多少是实际上有问题的。

**下图是对混淆矩阵参数的详细解释图：**

![][3]

**相关指标：**

> Positive：表示正样本数（OK的曲线数）；Negative 表示负样本数（NOK的曲线数）。
>
> PP：表示预测为正的样本数（预测OK的曲线数）；PN表示预测为负的样本数（预测NOK的曲线数）。
>
> True Positive (TP)：把OK的曲线**成功**预测为OK的数量；
>
> True Negative (TN)：把NOK的曲线**成功**预测为NOK的数量；
>
> False Positive (FP)：把NOK的曲线**错误**地预测为OK的数量；
>
> False Negative (FN)：把OK的曲线**错误**的预测为NOK的数量。



**通过混淆矩阵和上文中的描述可以计算出Precision（精准度）和 Recall（召回率）。计算公式如下：**

**Recall**
$$

Recall = \frac{TN}{FP+TN} = \frac{ 718 }{ 2 + 718 } = 99.722 \% $$

**Precision**
$$ Precision = \frac{TN}{FN+TN} = \frac{ 718 }{ 2 + 718 } = 99.722 \% $$

<div style="page-break-after: always;"></div>

## 算法模型解释

**除了准确率，一个优秀的算法模型还应该关注哪些指标？**

对于异常检测算法而言，准确率是相当重要且直观的指标。但是准确率只是一个数字，不足以描述算法是否真的可靠。在实际的业务需求中，主要关注以下方面：

1. 算法模型是否会发生**误报**的情况导致生产停线？
2. 算法模型的泛化能力，是否对**各种业务场景**（不同的螺栓、工件）生效？
3. 算法模型拟合的数据量是否足够，是否存在**数据量不够**导致模型准确率低的情况？

**以下将通过ROC/AUC和学习曲线两个指标来说明这些问题。**



### （*）ROC/AUC

**阈值**：对于事物的评判标准，比如当一个东西超过2米时认为它高，低于2米时认为它低。则2米就是阈值。类比于曲线的分类，假如算法模型可以为曲线进行打分，则存在一个分数可以区别NOK和OK的曲线，则这个分数就是阈值。

ROC曲线是信号检测理论中用来选择最佳的信号侦测模型、舍弃次佳的模型的一种坐标图式的分析工具。它的横坐标是算法模型的**伪阳性率**，也就是算法模型误报的概率。它的纵坐标是**真阳性率**，也就是算法模型成功预测的概率。**它的点代表在某一个阈值下，算法模型的真阳性率与伪阳性率**。通过改变阈值得到不同的点，可以绘制如下曲线，因为当准确率较高时，误报率也就越低。所以这些点**越接近左上角说明准确率越高，算法模型越好**：

![][4]

TPR（真阳性率）：在所有实际为NOK曲线的样本中，被**正确地**判断为NOK之比率。
$$
TPR = \frac{TP}{TP+FN}
$$
FPR（伪阳性率）：在所有实际为NOK曲线的样本中，被**错误地**判断为OK之比率。
$$
FPR = \frac{FP}{FP+TN}
$$
可以发现ROC曲线的侧重点与Precision（精准度）/Recall（召回率）不同，它主要关注算法模型的预测性能，通过ROC曲线可以直观的对模型的预测能力以进行打分，也就是**AUC**。

AUC是ROC曲线下方的面积，因为是在1x1的方格里求面积，AUC必在0~1之间。假设阈值以上是NOK，以下是OK；若随机抽取一个NOK样本和一个OK样本，算法模型计算NOK样本的值高于OK样本值的概率。简单说：**AUC值越大的分类器，正确率越高。**

**下图是ROC的例子，以及怎样的ROC/AUC曲线才是更优秀的：**

一个常规的ROC-AUC曲线应该如下图所示，其中橘黄色的曲线越贴近左上方坐标轴，则表示模型的准确性越好，误报率越低，完美情况下左上角没有缝隙且ROC下的面积为1，表示模型预测的准确率为100%。

![][5]

因此对于一个算法模型而言，如果它的AUC非常接近1，那么它误报的可能性几乎为0，也就是算法模型是值得信任的。**不会因为误报了NOK导致发生停线等生产问题**。

> 蓝色的虚线表示模型没有起作用，如果ROC曲线接近这条虚线，说明算法的准确率与随机猜测等同。

<div style="page-break-after: always;"></div>

### Learning Curve（学习曲线）

学习曲线是机器学习中评价模型的常用手段，它可反映算法模型的泛化能力，是否足可以**应对不同的业务场景**，以及**模型的拟合程度**， 是否数据量有待提升。其分为两条曲线：红色曲线代表随着训练样本数的增加算法模型对训练集预测的准确率。绿色曲线代表随着训练样本数的增加算法模型对测试集预测的准确率。

![][6]

> 对于一个算法模型而言，随着样本数的增加其预测能力逐渐稳定，因此无论是算法模型对训练集还是测试集的预测结果都将趋于一个稳定而相近的值。这个值接近于算法最终的性能指标，同时可以设定期望值并对其进行比较，由此可以得到算法是否已经具备足够的准确性。

学习曲线中主要关注两个指标：**方差、偏差**。下图蓝色虚线为算法模型的期望值，红色与蓝色的实线为实际算法模型的学习曲线。

**方差和偏差如何理解可以看下图：**

![][7]

从上图可以得到当方差偏大时，预测数据的命中不能集中到一个点，**也就是准确率会比较低**。而当偏差较大时，预测数据的不能命中期望的目标，也就是**模型不具备实际作用**。

**下图是学习曲线的示例，可以对照上图进行分析：**


![][8]

图1 是一个正常拟合的算法模型的的学习曲线，它的分数达到了期望值，且**拟合程度较高**。

图2 中训练集和交叉验证集的准确率远低于预期值，说明模型**偏差较大（也就是模型并不具备足够的泛化能力）**，通常的原因是特征选取出现了问题，无论数据量如何提升也无法提高其准确性。

图3 中训练集和交叉验证集的拟合程度不高，出现了高方差的现象。通常是因为**数据量不够导致准确率不足**。需要增加训练集的数据量来进行优化。

**也就是说，曲线的形态越接近图1 得到的模型也就越好，它的泛化能力和数据量都是合格的。**

<div style="page-break-after: always;"></div>

## 算法模型特征

**什么是算法模型的特征？其重要性是什么？**

算法模型的特征是机器学习中的重要一环，如果特征选取的不好会造成如下问题：

1. 特征选取泛化能力太差，相同特征的算法模型对于当前螺栓工件控制器给出了相对较高的预测准确率，但是对于其他螺栓的预测则出现非常大的偏差。
2. 特征选取与业务或者事物属性无关，无论何种螺栓或者给定大量的数据也无法得到较高准确率，训练出的模型不具备可靠性。

**那如何判断特征选取是否优越，下文将对模型选取特征进行评价**



>  全局特征解释表示针对整个模型而言，特征的贡献度，是评价特征对于模型重要性的一种手段。
>
> 局部特征解释表示针对某个样本而言，特征的贡献度，是评价特征泛化能力的一种手段。

### 全局特征解释

对于整个模型通常会考虑的问题：

> 1. 哪些特征对于模型是最重要的
> 2. 从大量的记录整体考虑，每一个特征如何影响模型的预测

#### （*）Feature Shap Beeswarm（SHAP 蜂图）

SHAP 蜂图是一种全局的、可以评估特征选取造成影响的图表。可以从大量的记录整体考虑，每一个特征如何影响模型的预测。

**SHAP值**：可以理解为特征对于算法模型模型预测得到结果的贡献值。 

![][9]

为了大致了解哪些特征对模型最重要，可以绘制每个样本的每个特征的 SHAP 值。下图按所有样本的 SHAP 值大小之和对特征进行排序，并使用 SHAP 值显示每个特征对模型输出的影响分布。颜色代表特征值（红色高，蓝色低）。

对于分类算法而言在坐标轴的左侧，红色表示此特征会减小预测为NOK的概率，而在坐标轴右侧，红色表示此特征会增大预测为NOK的概率。

<div style="page-break-after: always;"></div>


[0]:feature_importance.png

[1]:流程图.png

[2]:confusion_matrix.png

[3]:混淆矩阵定义.png

[4]:roc_auc.png

[5]:ROC-example.png

[6]:learning_curve.png

[7]:学习曲线解释.jpg

[8]:LearnCurveExample.png

[9]:feature_beeswarm.png